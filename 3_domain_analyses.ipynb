{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Third-party libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import chi2_contingency, ttest_ind\n",
    "\n",
    "# Print current working directory\n",
    "curr_wd = os.path.abspath(os.getcwd())\n",
    "print(f\"Current working directory: {curr_wd}\")\n",
    "\n",
    "\n",
    "def get_go_term_details(go_id):\n",
    "    \"\"\"\n",
    "    Retrieve GO term details from EBI QuickGO API.\n",
    "\n",
    "    Parameters:\n",
    "        go_id (str): The GO term identifier.\n",
    "\n",
    "    Returns:\n",
    "        dict or None: Dictionary of GO term details or None if not found.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.ebi.ac.uk/QuickGO/services/ontology/go/terms/{go_id}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if \"results\" in data and data[\"results\"]:\n",
    "            term = data[\"results\"][0]\n",
    "            return {\n",
    "                \"id\": term[\"id\"],\n",
    "                \"name\": term[\"name\"],\n",
    "                \"namespace\": term[\"aspect\"],\n",
    "                \"definition\": term[\"definition\"][\"text\"]\n",
    "            }\n",
    "    return None\n",
    "\n",
    "\n",
    "def assign_group(protein, group1_list, group1_label, group2_list, group2_label):\n",
    "    \"\"\"\n",
    "    Assign a group label to a protein.\n",
    "\n",
    "    Parameters:\n",
    "        protein (str): Protein ID.\n",
    "        group1_list (list): Proteins in group 1.\n",
    "        group1_label (str): Label for group 1.\n",
    "        group2_list (list): Proteins in group 2.\n",
    "        group2_label (str): Label for group 2.\n",
    "\n",
    "    Returns:\n",
    "        str: Assigned group label.\n",
    "    \"\"\"\n",
    "    if protein in group1_list:\n",
    "        return group1_label\n",
    "    elif protein in group2_list:\n",
    "        return group2_label\n",
    "    else:\n",
    "        return 'Not in any group'\n",
    "\n",
    "\n",
    "def count_consecutive_stretches_of_1(lst, label=\"IDR\"):\n",
    "    \"\"\"\n",
    "    Find stretches of consecutive 1s in a list.\n",
    "\n",
    "    Parameters:\n",
    "        lst (list): List of binary values.\n",
    "        label (str): Label to assign to each stretch.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Start, end, and label of each stretch.\n",
    "    \"\"\"\n",
    "    stretches = []\n",
    "    in_stretch = False\n",
    "    for i, val in enumerate(lst):\n",
    "        if val == 1 and not in_stretch:\n",
    "            start = i\n",
    "            in_stretch = True\n",
    "        elif val == 0 and in_stretch:\n",
    "            stretches.append((start, i, label))\n",
    "            in_stretch = False\n",
    "    if in_stretch:\n",
    "        stretches.append((start, len(lst), label))\n",
    "    return stretches\n",
    "\n",
    "\n",
    "def is_either_between(low, high, start, end):\n",
    "    \"\"\"\n",
    "    Check if either endpoint of a motif is within a given range.\n",
    "\n",
    "    Parameters:\n",
    "        low (int): Lower bound of range.\n",
    "        high (int): Upper bound of range.\n",
    "        start (int): Start of motif.\n",
    "        end (int): End of motif.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if either motif endpoint is within range.\n",
    "    \"\"\"\n",
    "    return (low <= start <= high) or (low <= end <= high)\n",
    "\n",
    "\n",
    "def merge_duplicates(input_string):\n",
    "    \"\"\"\n",
    "    Remove consecutive duplicate characters from a string.\n",
    "\n",
    "    Parameters:\n",
    "        input_string (str): The input string.\n",
    "\n",
    "    Returns:\n",
    "        str: String with consecutive duplicates removed.\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    prev_char = None\n",
    "    for char in input_string:\n",
    "        if char != prev_char:\n",
    "            result += char\n",
    "            prev_char = char\n",
    "    return result\n",
    "\n",
    "\n",
    "def cat_string(input_string):\n",
    "    \"\"\"\n",
    "    Categorize input string pattern based on motif patterns.\n",
    "\n",
    "    Parameters:\n",
    "        input_string (str): The motif pattern string.\n",
    "\n",
    "    Returns:\n",
    "        str: Category label for the input string.\n",
    "    \"\"\"\n",
    "    if \"DIDI\" in input_string and \"IDID\" in input_string:\n",
    "        return \"more\\ncomplex\"\n",
    "    elif \"IDID\" in input_string:\n",
    "        return \"IDID\"\n",
    "    elif \"DIDI\" in input_string:\n",
    "        return \"DIDI\"\n",
    "    elif \"IDI\" in input_string:\n",
    "        return \"IDI\"\n",
    "    elif \"DID\" in input_string:\n",
    "        return \"DID\"\n",
    "    elif \"ID\" in input_string:\n",
    "        return \"ID\"\n",
    "    elif \"DI\" in input_string:\n",
    "        return \"DI\"\n",
    "    elif \"I\" in input_string:\n",
    "        return \"I\"\n",
    "    elif \"D\" in input_string:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"None\"\n",
    "\n",
    "def make_struct_string(region_list):\n",
    "    \"\"\"\n",
    "    Convert a list of annotated regions to a structural string representation.\n",
    "\n",
    "    Parameters:\n",
    "        region_list (list of tuples): Each tuple ends with a region type \n",
    "                                      (e.g., \"IDR\", \"MOTIF\", \"NABIND\", \"DOMAIN\").\n",
    "\n",
    "    Returns:\n",
    "        str: Structural string where each region is represented by a single character.\n",
    "    \"\"\"\n",
    "    struct_string = \"\"\n",
    "    mapping = {\n",
    "        \"IDR\": \"I\",\n",
    "        \"MOTIF\": \"M\",\n",
    "        \"NABIND\": \"R\",\n",
    "        \"DOMAIN\": \"D\"\n",
    "    }\n",
    "\n",
    "    for _, _, label in region_list:\n",
    "        struct_string += mapping.get(label, \"\")\n",
    "    return struct_string\n",
    "\n",
    "\n",
    "def assign_groups_advanced(\n",
    "    protein,\n",
    "    group1_list, group1_label,\n",
    "    group2_list, group2_label,\n",
    "    group3_list, group3_label,\n",
    "    group4_list, group4_label\n",
    "):\n",
    "    \"\"\"\n",
    "    Assign a protein to one of four groups based on membership.\n",
    "\n",
    "    Parameters:\n",
    "        protein (str): Protein ID.\n",
    "        groupX_list (list): List of proteins in group X.\n",
    "        groupX_label (str): Label for group X.\n",
    "\n",
    "    Returns:\n",
    "        str: Assigned group label or 'Not in any group'.\n",
    "    \"\"\"\n",
    "    if protein in group1_list:\n",
    "        return group1_label\n",
    "    elif protein in group2_list:\n",
    "        return group2_label\n",
    "    elif protein in group3_list:\n",
    "        return group3_label\n",
    "    elif protein in group4_list:\n",
    "        return group4_label\n",
    "    else:\n",
    "        return 'Not in any group'\n",
    "\n",
    "\n",
    "def calculate_domain_motif_distance(domain, motif, mode):\n",
    "    \"\"\"\n",
    "    Calculate the distance between a domain and a motif in a protein.\n",
    "\n",
    "    Parameters:\n",
    "        domain (tuple): (start, end) of the domain.\n",
    "        motif (tuple): (start, end) of the motif.\n",
    "        mode (str): 'e' for edge-based distance, 'c' for center-based distance.\n",
    "\n",
    "    Returns:\n",
    "        int or float: Distance between domain and motif. If overlapping, returns 0.\n",
    "    \"\"\"\n",
    "    start1, end1 = domain\n",
    "    start2, end2 = motif\n",
    "\n",
    "    if mode == \"e\":\n",
    "        if max(start1, start2) <= min(end1, end2):  # overlapping\n",
    "            return 0\n",
    "        elif start1 < start2:  # domain left of motif\n",
    "            return start2 - end1\n",
    "        else:  # domain right of motif\n",
    "            return end2 - start1\n",
    "    elif mode == \"c\":\n",
    "        domain_center = start1 + (end1 - start1) / 2\n",
    "        motif_center = start2 + (end2 - start2) / 2\n",
    "        if max(start1, start2) <= min(end1, end2):  # overlapping\n",
    "            return 0\n",
    "        else:\n",
    "            return motif_center - domain_center\n",
    "\n",
    "\n",
    "# Load annotated datasets\n",
    "motif_info_set_df = pd.read_parquet(\n",
    "    os.path.join(curr_wd, 'data/processed/GAR_motif_Wang_set_human_cleaned_annot_filtered.parquet')\n",
    ")\n",
    "annotated_IDR_df = pd.read_parquet(\n",
    "    os.path.join(curr_wd, 'data/processed/annotation_datasets/all_IDR_human.parquet')\n",
    ")\n",
    "annotated_domain_df = pd.read_parquet(\n",
    "    os.path.join(curr_wd, 'data/processed/annotation_datasets/all_domains_human.parquet')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver = \"v3\"\n",
    "\n",
    "# Define named sets and their associated file names\n",
    "set_definitions = {\n",
    "    \"GAR_full\": [\"GAR_subset_full\"],\n",
    "    \"GAR_LLPS_pos\": [\n",
    "        \"4_LLPS_positive_set_and_GAR_subset\",\n",
    "        \"5_LLPS_positive_set_and_NA_positive_set_and_GAR_subset\"\n",
    "    ],\n",
    "    \"GAR_LLPS_pos_NA_neg\": [\"4_LLPS_positive_set_and_GAR_subset\"],\n",
    "    \"GAR_LLPS_neg\": [\n",
    "        \"6_NA_positive_set_and_GAR_subset\",\n",
    "        \"7_GAR_subset_only\"\n",
    "    ],\n",
    "    \"GAR_LLPS_neg_NA_pos\": [\"6_NA_positive_set_and_GAR_subset\"],\n",
    "    \"GAR_NA_pos\": [\n",
    "        \"5_LLPS_positive_set_and_NA_positive_set_and_GAR_subset\",\n",
    "        \"6_NA_positive_set_and_GAR_subset\"\n",
    "    ],\n",
    "    \"GAR_NA_neg\": [\n",
    "        \"4_LLPS_positive_set_and_GAR_subset\",\n",
    "        \"7_GAR_subset_only\"\n",
    "    ],\n",
    "    \"GAR_pos\": [\"5_LLPS_positive_set_and_NA_positive_set_and_GAR_subset\"],\n",
    "    \"GAR_neg\": [\"7_GAR_subset_only\"],\n",
    "}\n",
    "\n",
    "# Initialize dictionaries and containers\n",
    "set_dict = {}\n",
    "set_list = []\n",
    "proteins_sets_dict = {}\n",
    "\n",
    "# Load each set of proteins from its respective files\n",
    "for set_name, file_names in set_definitions.items():\n",
    "    proteins = []\n",
    "    for fname in file_names:\n",
    "        file_path = f\"{curr_wd}/data/processed/final_set_lists/{fname}.txt\"\n",
    "        with open(file_path, \"r\") as f:\n",
    "            proteins.extend(line.strip() for line in f)\n",
    "    set_dict[set_name] = proteins\n",
    "    set_list.append(proteins)\n",
    "\n",
    "# Load full proteome\n",
    "full_proteome_path = f\"{curr_wd}/data/processed/list_of_human_proteins.csv\"\n",
    "with open(full_proteome_path, \"r\") as f:\n",
    "    full_proteome = [line.strip() for line in f]\n",
    "set_dict[\"full_proteome\"] = full_proteome\n",
    "set_list.append(full_proteome)\n",
    "\n",
    "# Store sets in versioned dictionary\n",
    "set_names = list(set_dict.keys())\n",
    "proteins_sets_dict[ver] = set_dict\n",
    "\n",
    "# Extract positive and negative protein lists\n",
    "pos_prot_list = set_dict[\"GAR_pos\"]\n",
    "neg_prot_list = set_dict[\"GAR_neg\"]\n",
    "set_prot_list = list(set(pos_prot_list + neg_prot_list))\n",
    "\n",
    "# Filter for Pfam-annotated domains\n",
    "pfam_annotated_domain_df = annotated_domain_df[\n",
    "    annotated_domain_df['databases'].apply(lambda x: \"pfam\" in x)\n",
    "]\n",
    "\n",
    "# Build dictionary of domain → GO ID list (non-empty only)\n",
    "domain_GO_dict = {\n",
    "    row['name']: row['GO_identifiers']\n",
    "    for _, row in pfam_annotated_domain_df.iterrows()\n",
    "    if len(row['GO_identifiers']) > 0\n",
    "}\n",
    "\n",
    "print(f\"Domains with GO annotations: {len(domain_GO_dict)}\")\n",
    "\n",
    "# Collect and deduplicate all GO terms\n",
    "all_GO_terms = []\n",
    "for value in domain_GO_dict.values():\n",
    "    if isinstance(value, (list, np.ndarray)):\n",
    "        all_GO_terms.extend(map(str, value))\n",
    "    else:\n",
    "        all_GO_terms.append(str(value))\n",
    "\n",
    "print(f\"Total GO term entries (before deduplication): {len(all_GO_terms)}\")\n",
    "all_GO_terms = list(set(all_GO_terms))\n",
    "print(f\"Unique GO terms: {len(all_GO_terms)}\")\n",
    "# print(all_GO_terms)\n",
    "\n",
    "# Build GO ID → GO name dictionary from annotated domains\n",
    "GO_ID_dict = {}\n",
    "for _, row in annotated_domain_df.iterrows():\n",
    "    ids = row.get(\"GO_identifiers\", [])\n",
    "    names = row.get(\"GO_names\", [])\n",
    "    GO_ID_dict.update(dict(zip(ids, names)))\n",
    "\n",
    "print(f\"GO term name mappings: {len(GO_ID_dict)}\")\n",
    "# print(\"Resulting Dictionary:\", GO_ID_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of domain names in full and Pfam-annotated domain dataframes\n",
    "occurrences_all = annotated_domain_df['name'].value_counts().to_dict()\n",
    "print(f\"Total unique domains (all): {len(occurrences_all)}\")\n",
    "\n",
    "occurrences_pfam = pfam_annotated_domain_df['name'].value_counts().to_dict()\n",
    "print(f\"Total unique Pfam domains: {len(occurrences_pfam)}\")\n",
    "\n",
    "# Filter domains occurring at least 100 times\n",
    "occurrences_pfam_filtered = {k: v for k, v in occurrences_pfam.items() if v >= 100}\n",
    "print(f\"Domains with >=100 occurrences: {len(occurrences_pfam_filtered)}\")\n",
    "\n",
    "# List of filtered domain names\n",
    "domains_to_check = list(occurrences_pfam_filtered.keys())\n",
    "print(f\"Filtered domains to check: {domains_to_check}\")\n",
    "print(f\"Number of filtered domains: {len(domains_to_check)}\")\n",
    "\n",
    "# Sort filtered domains by occurrences in descending order\n",
    "sorted_domains = dict(sorted(occurrences_pfam_filtered.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Separate keys and values for plotting\n",
    "domain_names = list(sorted_domains.keys())\n",
    "domain_counts = list(sorted_domains.values())\n",
    "\n",
    "# Plot bar chart of occurrences\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(domain_names, domain_counts, color='skyblue')\n",
    "plt.xlabel('Domain Names')\n",
    "plt.ylabel('Occurrences')\n",
    "plt.title('Occurrences of Pfam Domains with >=100 Counts')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = \"GO_identifiers\"  # Replace with your column name\n",
    "rows_with_empty_list_or_array = pfam_annotated_domain_df[column_name].apply(\n",
    "    lambda x: isinstance(x, (list, np.ndarray)) and len(x) == 0\n",
    ").sum()\n",
    "print(f\"Rows with empty lists in column '{column_name}':\", rows_with_empty_list_or_array)\n",
    "\n",
    "# Load GO terms related to nucleic acid binding\n",
    "with open(curr_wd + '/data/external/InterPro/' + 'GO_terms_NAbinding.txt', \"r\") as f:\n",
    "    list_of_GO_terms_withNAbinding = f.read().strip().split(\"\\n\")\n",
    "\n",
    "# Initialize output dictionary\n",
    "protein_dict_with_domain_metrics = {}\n",
    "\n",
    "# Iterate over proteins in the full proteome\n",
    "full_proteome = proteins_sets_dict['v3']['full_proteome']\n",
    "for i, curr_protein in enumerate(full_proteome):\n",
    "    # Skip if no motif info available\n",
    "    if motif_info_set_df[motif_info_set_df[\"UniqueID\"] == curr_protein].empty:\n",
    "        continue\n",
    "\n",
    "    print(f\"{i} out of {len(full_proteome)} — {curr_protein}\")\n",
    "\n",
    "    # Initialize default metrics\n",
    "    protein_dict_with_domain_metrics[curr_protein] = {\n",
    "        \"num_of_IDR\": 0,\n",
    "        \"structure_string\": \"\",\n",
    "        \"num_domains\": 0\n",
    "    }\n",
    "\n",
    "    # Get IDR annotation if available\n",
    "    if annotated_IDR_df[annotated_IDR_df[\"protein_name\"] == curr_protein].empty:\n",
    "        list_of_IDRs = []\n",
    "        list_of_IDRs_unchanged = []\n",
    "    else:\n",
    "        curr_IDR_info = annotated_IDR_df.loc[\n",
    "            annotated_IDR_df[\"protein_name\"] == curr_protein,\n",
    "            \"prediction-disorder-mobidb_lite\"\n",
    "        ].tolist()[0].tolist()\n",
    "\n",
    "        list_of_IDRs = count_consecutive_stretches_of_1(curr_IDR_info)\n",
    "        list_of_IDRs_unchanged = count_consecutive_stretches_of_1(curr_IDR_info)\n",
    "\n",
    "        # Label IDRs overlapping with motifs\n",
    "        motif_rows = motif_info_set_df[motif_info_set_df[\"UniqueID\"] == curr_protein]\n",
    "        for idx, idr_region in enumerate(list_of_IDRs):\n",
    "            for _, motif in motif_rows[[\"start\", \"end\"]].iterrows():\n",
    "                if is_either_between(idr_region[0], idr_region[1], motif['start'], motif['end']):\n",
    "                    list_of_IDRs[idx] = (idr_region[0], idr_region[1], \"MOTIF\")\n",
    "                    break\n",
    "\n",
    "    # Get domain annotations\n",
    "    curr_domain_info = pfam_annotated_domain_df[\n",
    "        pfam_annotated_domain_df['protein_name'] == curr_protein\n",
    "    ]\n",
    "\n",
    "    list_of_domains = []\n",
    "    list_of_domains_R = []\n",
    "    for _, row in curr_domain_info.iterrows():\n",
    "        domain_tuple = (row['start'], row['end'], row['name'])\n",
    "        list_of_domains.append(domain_tuple)\n",
    "\n",
    "        # Annotate based on NA-binding GO terms\n",
    "        if set(row['GO_identifiers']).intersection(list_of_GO_terms_withNAbinding):\n",
    "            list_of_domains_R.append((row['start'], row['end'], \"NABIND\"))\n",
    "        else:\n",
    "            list_of_domains_R.append((row['start'], row['end'], \"DOMAIN\"))\n",
    "\n",
    "    # Combine and sort domains and IDRs\n",
    "    combined_features = sorted(list_of_domains_R + list_of_IDRs, key=lambda x: x[0])\n",
    "    combined_features_old = sorted(list_of_domains_R + list_of_IDRs_unchanged, key=lambda x: x[0])\n",
    "\n",
    "    # Store results\n",
    "    protein_dict_with_domain_metrics[curr_protein] = {\n",
    "        \"num_of_IDR\": len(list_of_IDRs),\n",
    "        \"structure_string\": make_struct_string(combined_features),\n",
    "        \"structure_string_old\": make_struct_string(combined_features_old),\n",
    "        \"num_domains\": len(list_of_domains),\n",
    "        \"domains\": list_of_domains,\n",
    "        \"IDR_bounds\": list_of_IDRs\n",
    "    }\n",
    "\n",
    "# Convert to DataFrame\n",
    "proteins_with_domain_metrics_df = pd.DataFrame(protein_dict_with_domain_metrics).transpose()\n",
    "proteins_with_domain_metrics_df.reset_index(inplace=True)\n",
    "proteins_with_domain_metrics_df.rename(columns={'index': 'proteins'}, inplace=True)\n",
    "\n",
    "# Annotate group (pos/neg)\n",
    "proteins_with_domain_metrics_df['Group'] = proteins_with_domain_metrics_df['proteins'].apply(\n",
    "    assign_group, args=(pos_prot_list, \"pos\", neg_prot_list, \"neg\")\n",
    ")\n",
    "\n",
    "# Create reduced structure strings\n",
    "proteins_with_domain_metrics_df['reduced_struct_string'] = proteins_with_domain_metrics_df['structure_string'].apply(merge_duplicates)\n",
    "proteins_with_domain_metrics_df['reduced_struct_string_old'] = proteins_with_domain_metrics_df['structure_string_old'].apply(merge_duplicates)\n",
    "proteins_with_domain_metrics_df['categ_reduced_struct_string_old'] = proteins_with_domain_metrics_df['reduced_struct_string_old'].apply(cat_string)\n",
    "\n",
    "# Convert dtypes\n",
    "proteins_with_domain_metrics_df = proteins_with_domain_metrics_df.infer_objects()\n",
    "print(proteins_with_domain_metrics_df.dtypes)\n",
    "\n",
    "# Final output\n",
    "proteins_with_domain_metrics_df\n",
    "\n",
    "output_path = f\"{curr_wd}/data/results/proteins_with_domain_metrics_df.pkl\"\n",
    "with open(output_path, \"wb\") as fp:\n",
    "    pickle.dump(proteins_with_domain_metrics_df, fp)\n",
    "    print(\"DataFrame saved successfully to file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{curr_wd}/data/results/proteins_with_domain_metrics_df.pkl\", 'rb') as fp:\n",
    "    proteins_with_domain_metrics_df = pickle.load(fp)\n",
    "proteins_with_domain_metrics_df\n",
    "\n",
    "proteins_with_domain_metrics_df[\"domains_number\"] = proteins_with_domain_metrics_df['domains'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "print(proteins_with_domain_metrics_df[proteins_with_domain_metrics_df[\"Group\"] == 'pos'].domains_number.value_counts())\n",
    "print(proteins_with_domain_metrics_df[proteins_with_domain_metrics_df[\"Group\"] == 'neg'].domains_number.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "\n",
    "# Function to conditionally display absolute numbers\n",
    "def conditional_autopct(pct, all_values):\n",
    "    absolute = int(round(pct * sum(all_values) / 100.0))\n",
    "    return f\"{absolute}\" if absolute > 1 else \"\"\n",
    "\n",
    "# Label mapping for domain counts\n",
    "custom_label_dict = {\n",
    "    0: \"no domains\",\n",
    "    1: \"1 domain\",\n",
    "    2: \"2 domains\",\n",
    "    3: \"3 domains\",\n",
    "    4: \"4 domains\",\n",
    "    \"more than 4\": \"≥ 5 domains\"\n",
    "}\n",
    "\n",
    "# --- Prepare data ---\n",
    "def preprocess_group_data(df, group_name):\n",
    "    group_df = df[df[\"Group\"] == group_name]\n",
    "    domain_counts = group_df['domains_number'].value_counts().sort_index()\n",
    "    grouped_counts = domain_counts.groupby(lambda x: \"more than 4\" if x > 4 else x).sum()\n",
    "    custom_labels = [custom_label_dict.get(label, label) for label in grouped_counts.index]\n",
    "    return grouped_counts, custom_labels, len(group_df)\n",
    "\n",
    "data_pos, labels_pos, pos_len = preprocess_group_data(proteins_with_domain_metrics_df, \"pos\")\n",
    "data_neg, labels_neg, neg_len = preprocess_group_data(proteins_with_domain_metrics_df, \"neg\")\n",
    "\n",
    "# --- Plotting ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 5))\n",
    "palette = sns.color_palette(\"OrRd\", 7)\n",
    "palette[0] = 'lightgrey'\n",
    "\n",
    "def plot_donut(ax, data, labels, title_text):\n",
    "    wedges, _, autotexts = ax.pie(\n",
    "        data.values,\n",
    "        colors=palette,\n",
    "        autopct=lambda pct: conditional_autopct(pct, data.values),\n",
    "        startangle=90,\n",
    "        wedgeprops=dict(width=0.4)\n",
    "    )\n",
    "    ax.text(0, 0, title_text, ha='center', va='center', fontsize=12)\n",
    "    for autotext in autotexts:\n",
    "        pos = autotext.get_position()\n",
    "        autotext.set_position((pos[0] * 1.3, pos[1] * 1.3))\n",
    "        autotext.set_fontsize(12)\n",
    "    return wedges\n",
    "\n",
    "# Positive group plot\n",
    "wedges_pos = plot_donut(axes[0], data_pos, labels_pos, f\"positive group\\nn={pos_len}\")\n",
    "\n",
    "# Negative group plot\n",
    "wedges_neg = plot_donut(axes[1], data_neg, labels_neg, f\"negative group\\nn={neg_len}\")\n",
    "\n",
    "# Legend\n",
    "axes[1].legend(wedges_pos, labels_pos, title=\"# of domains\", loc=\"center left\", bbox_to_anchor=(1, 0.5),\n",
    "               fontsize=11, title_fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "os.makedirs(os.path.join(curr_wd, \"data/results/subfigures/\"), exist_ok=True)\n",
    "plt.savefig(os.path.join(curr_wd, \"data/results/subfigures/fig2_A_B.svg\"), transparent=True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- Utility functions ---\n",
    "def extract_domains(df, group_name, domain_GO_dict):\n",
    "    \"\"\"Prepare domain data for a specific group (pos/neg).\"\"\"\n",
    "    group_df = df[df[\"Group\"] == group_name].explode(\"domains\").reset_index(drop=True)\n",
    "    group_df[\"domain_name\"] = group_df[\"domains\"].apply(lambda x: x[2] if isinstance(x, tuple) else \"no domain\")\n",
    "    group_df[\"GO_terms\"] = group_df[\"domain_name\"].apply(lambda x: domain_GO_dict.get(x, \"no GO term\"))\n",
    "    return group_df[group_df[\"domain_name\"] != \"no domain\"]\n",
    "\n",
    "\n",
    "def simple_barplot(data_main, data_ref, mode, min_apps=10, label_dict=None):\n",
    "    if label_dict is None:\n",
    "        label_dict = {}\n",
    "\n",
    "    # Color settings\n",
    "    if mode == 'positive':\n",
    "        main_color, ref_color = \"#8DB600\", \"#FF4040\"\n",
    "    elif mode == 'negative':\n",
    "        main_color, ref_color = \"#FF4040\", \"#8DB600\"\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be 'positive' or 'negative'.\")\n",
    "\n",
    "    # Filter by minimum count\n",
    "    filtered = {k: v for k, v in data_main.items() if v >= min_apps}\n",
    "    keys = list(filtered.keys())\n",
    "    values = list(filtered.values())\n",
    "    ref_values = [data_ref.get(k, 0) for k in keys]\n",
    "\n",
    "    fig = plt.figure(figsize=(3.5, len(keys) * 0.35))\n",
    "\n",
    "    y_positions = np.arange(len(keys))\n",
    "    bars = plt.barh(y_positions, values, color=main_color, edgecolor='black', height=0.75, alpha=0.75)\n",
    "\n",
    "    # Add text labels on the left of bars\n",
    "    for y, key in enumerate(keys):\n",
    "        label = label_dict.get(key, key)\n",
    "        plt.text(plt.gca().get_xlim()[1] * 0.01, y, label, ha='left', va='center', fontsize=10)\n",
    "\n",
    "    # Aesthetic settings\n",
    "    plt.xlabel('# of domain appearances')\n",
    "    plt.yticks([])  # Hide y-axis ticks\n",
    "    if mode == \"negative\":\n",
    "        plt.xticks(ticks=range(0, 15, 2))\n",
    "\n",
    "    plt.grid(axis='x', linestyle='--', zorder=0)\n",
    "    plt.gca().set_axisbelow(True)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.ylim(len(keys) + 1.5, -0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(os.path.join(curr_wd, \"data/results/subfigures/\"), exist_ok=True)\n",
    "    if mode == \"positive\":\n",
    "        plt.savefig(os.path.join(curr_wd, \"data/results/subfigures/fig2_C.svg\"), transparent=True)\n",
    "    else:\n",
    "        plt.savefig(os.path.join(curr_wd, \"data/results/subfigures/fig2_D.svg\"), transparent=True)\n",
    "    plt.show()\n",
    "\n",
    "# --- Main processing ---\n",
    "# Define custom label(s) if needed\n",
    "label_dict = {\n",
    "    \"Serine-threonine/tyrosine-protein kinase, catalytic domain\": \"Ser-Thr/Tyr protein kinase\"\n",
    "}\n",
    "\n",
    "# Prepare domain data for both groups\n",
    "data_pos_nod = extract_domains(proteins_with_domain_metrics_df, 'pos', domain_GO_dict)\n",
    "data_neg_nod = extract_domains(proteins_with_domain_metrics_df, 'neg', domain_GO_dict)\n",
    "\n",
    "# Generate value count dictionaries\n",
    "counts_pos = data_pos_nod[\"domain_name\"].value_counts().to_dict()\n",
    "counts_neg = data_neg_nod[\"domain_name\"].value_counts().to_dict()\n",
    "\n",
    "# --- Plotting ---\n",
    "simple_barplot(counts_pos, counts_neg, mode=\"positive\", min_apps=5, label_dict=label_dict)\n",
    "simple_barplot(counts_neg, counts_pos,  mode=\"negative\", min_apps=5, label_dict=label_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GO terms preparation\n",
    "data_pos_nog = data_pos_nod.explode(\"GO_terms\")\n",
    "print(len(data_pos_nog.GO_terms.value_counts()))\n",
    "\n",
    "data_neg_nog = data_neg_nod.explode(\"GO_terms\")\n",
    "print(len(data_neg_nog.GO_terms.value_counts()))\n",
    "\n",
    "\n",
    "def simple_barplot_GO(cdp, cdn, mode, min_apps=10, label_dict=None):\n",
    "    if label_dict is None:\n",
    "        label_dict = {}\n",
    "\n",
    "    if mode == 'positive':\n",
    "        data_dict = cdp\n",
    "        side_dict = cdn\n",
    "        main_color = \"#8DB600\"\n",
    "        side_color = '#FF4040'\n",
    "    elif mode == \"negative\":\n",
    "        data_dict = cdn\n",
    "        side_dict = cdp\n",
    "        main_color = '#FF4040'\n",
    "        side_color = \"#8DB600\"\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be 'positive' or 'negative'\")\n",
    "\n",
    "    # Filter GO terms by minimum count\n",
    "    filtered_data = {key: value for key, value in data_dict.items() if value >= min_apps}\n",
    "    keys = list(filtered_data.keys())\n",
    "    values = list(filtered_data.values())\n",
    "\n",
    "    fig = plt.figure(figsize=(3.5, len(keys) * 0.35))\n",
    "    y_positions = np.arange(len(keys))\n",
    "\n",
    "    # Plot main bars\n",
    "    bars = plt.barh(\n",
    "        keys,\n",
    "        values,\n",
    "        color=main_color,\n",
    "        edgecolor='black',\n",
    "        label='Main Values',\n",
    "        height=0.75,\n",
    "        alpha=0.75\n",
    "    )\n",
    "\n",
    "    # Annotate each bar\n",
    "    for idx, key in enumerate(keys):\n",
    "        label = GO_ID_dict.get(key, key)\n",
    "        if label == \"regulation of DNA-templated transcription\":\n",
    "            label = \"reg. of DNA-templ. transcription\"\n",
    "\n",
    "        category = get_go_term_details(key)\n",
    "        if category is None:\n",
    "            label = \"no functional annotation\"\n",
    "        elif category[\"namespace\"] == \"biological_process\":\n",
    "            label += \" (BP)\"\n",
    "        elif category[\"namespace\"] == \"cellular_component\":\n",
    "            label += \" (CC)\"\n",
    "        elif category[\"namespace\"] == \"molecular_function\":\n",
    "            label += \" (MF)\"\n",
    "\n",
    "        plt.text(\n",
    "            plt.gca().get_xlim()[1] * 0.01,\n",
    "            idx,\n",
    "            label,\n",
    "            ha='left',\n",
    "            va='center',\n",
    "            rotation=0\n",
    "        )\n",
    "\n",
    "    # Plot formatting\n",
    "    plt.xlabel('# of domain appearances')\n",
    "    plt.yticks(ticks=[], labels=[])\n",
    "    plt.grid(axis='x', linestyle='--', zorder=0)\n",
    "    plt.gca().set_axisbelow(True)\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    os.makedirs(os.path.join(curr_wd, \"data/results/subfigures/\"), exist_ok=True)\n",
    "    if mode == \"positive\":\n",
    "        plt.savefig(os.path.join(curr_wd, \"data/results/subfigures/fig2_E.svg\"), transparent=True)\n",
    "    else:\n",
    "        plt.savefig(os.path.join(curr_wd, \"data/results/subfigures/fig2_F.svg\"), transparent=True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run plots\n",
    "simple_barplot_GO(\n",
    "    data_pos_nog.GO_terms.value_counts().to_dict(),\n",
    "    data_neg_nog.GO_terms.value_counts().to_dict(),\n",
    "    mode=\"positive\",\n",
    "    min_apps=10,\n",
    "    label_dict=label_dict\n",
    ")\n",
    "\n",
    "simple_barplot_GO(\n",
    "    data_pos_nog.GO_terms.value_counts().to_dict(),\n",
    "    data_neg_nog.GO_terms.value_counts().to_dict(),\n",
    "    mode=\"negative\",\n",
    "    min_apps=10,\n",
    "    label_dict=label_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_motif_distances(df, motif_info_df, domain_GO_dict, view_limit, label_dict={}, show_singular_domains=False):\n",
    "    def flatten(lst):\n",
    "        return [item for sublist in lst for item in sublist]\n",
    "\n",
    "    data_by_group = {}\n",
    "    y_tick_counts = []\n",
    "\n",
    "    for group_label in [\"pos\", \"neg\"]:\n",
    "        filtered_df = df[df[\"Group\"] == group_label].explode(\"domains\").dropna(subset=['domains']).reset_index(drop=True)\n",
    "        domains = set(filtered_df['domains'].apply(lambda x: x[2]))\n",
    "\n",
    "        domain_motif_distances = {domain: ([], []) for domain in domains}\n",
    "\n",
    "        for domain in domains:\n",
    "            domain_df = filtered_df[filtered_df[\"domains\"].apply(lambda x: x[2] == domain)]\n",
    "            for _, row in domain_df.iterrows():\n",
    "                protein_id = row[\"proteins\"]\n",
    "                motifs = motif_info_df[motif_info_df[\"UniqueID\"] == protein_id]\n",
    "                motif_count = len(motifs)\n",
    "                domain_count = len(filtered_df[filtered_df[\"proteins\"] == protein_id])\n",
    "\n",
    "                for _, motif_row in motifs.iterrows():\n",
    "                    distance = calculate_domain_motif_distance(row['domains'][:2], (motif_row[\"start\"], motif_row[\"end\"]), \"c\")\n",
    "                    if domain_count == 1 and motif_count == 1:\n",
    "                        domain_motif_distances[domain][1].append(distance)\n",
    "                    else:\n",
    "                        domain_motif_distances[domain][0].append(distance)\n",
    "\n",
    "        def get_GO_filtered_lists(go_id):\n",
    "            return [domain_motif_distances[dom][i] for dom in domain_motif_distances if go_id in domain_GO_dict.get(dom, [])]\n",
    "\n",
    "        all_combined = (\n",
    "            flatten([domain_motif_distances[dom][0] for dom in domain_motif_distances]),\n",
    "            flatten([domain_motif_distances[dom][1] for dom in domain_motif_distances]),\n",
    "        )\n",
    "        domain_motif_distances[\"All domains combined\"] = all_combined\n",
    "\n",
    "        # Trim by view_limit\n",
    "        domain_motif_distances_trimmed = {\n",
    "            dom: ([x for x in lst0 if abs(x) <= view_limit], [x for x in lst1 if abs(x) <= view_limit])\n",
    "            for dom, (lst0, lst1) in domain_motif_distances.items()\n",
    "        }\n",
    "\n",
    "        # Sort by total number of data points\n",
    "        sorted_domains = sorted(domain_motif_distances_trimmed.items(), key=lambda x: len(x[1][0]) + len(x[1][1]), reverse=True)\n",
    "        selected_domains = [dom for dom, (lst0, lst1) in sorted_domains if len(lst0) + len(lst1) > 9]\n",
    "\n",
    "        y_tick_counts.append(len(selected_domains))\n",
    "        data_by_group[group_label] = {\n",
    "            \"domain_motif_distances\": domain_motif_distances,\n",
    "            \"selected_domains\": selected_domains\n",
    "        }\n",
    "\n",
    "    # Plot setup\n",
    "    height_ratios = [count / sum(y_tick_counts) for count in y_tick_counts]\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, sum(y_tick_counts)/3.25), sharex=True, gridspec_kw={'height_ratios': height_ratios})\n",
    "\n",
    "    for ax, group_label in zip(axes, [\"pos\", \"neg\"]):\n",
    "        group_data = data_by_group[group_label]\n",
    "        domains = group_data[\"selected_domains\"]\n",
    "        distances = group_data[\"domain_motif_distances\"]\n",
    "\n",
    "        domain_idx_map = {domain: idx for idx, domain in enumerate(domains)}\n",
    "        colors = plt.get_cmap(\"tab10\").colors\n",
    "\n",
    "        for i, domain in enumerate(domains):\n",
    "            if i % 2 == 0:\n",
    "                ax.axhspan(i - 0.5, i + 0.5, color='lightgrey', alpha=0.5)\n",
    "\n",
    "        for idx, domain in enumerate(domains):\n",
    "            color = \"black\" if domain == \"All domains combined\" else colors[idx % len(colors)]\n",
    "            dotalpha = 0.25 if domain == \"All domains combined\" else 0.5\n",
    "            dotsize = 50 if domain == \"All domains combined\" else 175\n",
    "            crosssize = 25 if domain == \"All domains combined\" else 75\n",
    "\n",
    "            x_vals, special_x_vals = distances[domain]\n",
    "            y_vals = [domain_idx_map[domain] + np.random.uniform(-0.30, 0.30) for _ in x_vals]\n",
    "            special_y_vals = [domain_idx_map[domain] + np.random.uniform(-0.30, 0.30) for _ in special_x_vals]\n",
    "\n",
    "            ax.scatter(x_vals, y_vals, alpha=dotalpha, label=domain, color=color, s=dotsize, marker=\".\", edgecolor=\"black\")\n",
    "\n",
    "            if show_singular_domains:\n",
    "                ax.scatter(special_x_vals, special_y_vals, marker='x', color=color, alpha=1.0, s=crosssize)\n",
    "            else:\n",
    "                ax.scatter(special_x_vals, special_y_vals, alpha=dotalpha, label=domain, color=color, s=dotsize, marker=\".\", edgecolor=\"black\")\n",
    "\n",
    "        ax.set_yticks(list(domain_idx_map.values()))\n",
    "        ax.set_yticklabels([label_dict.get(dom, dom) for dom in domain_idx_map], fontsize=11)\n",
    "        ax.grid(True, axis='x', linestyle='--', alpha=0.5)\n",
    "        ax.set_xlim(-view_limit, view_limit)\n",
    "        ax.set_ylim(-0.5, len(domains) - 0.5)\n",
    "\n",
    "    axes[1].set_xlabel('# of residues from the domain to the RG-motif', fontsize=11)\n",
    "    axes[0].text(view_limit * 1.03, y_tick_counts[0] // 2, \"positive\", rotation=90, fontsize=11, fontweight=\"bold\", va=\"center\")\n",
    "    axes[1].text(view_limit * 1.03, y_tick_counts[1] // 2, \"negative\", rotation=90, fontsize=11, fontweight=\"bold\", va=\"center\")\n",
    "    \n",
    "    fig.text(-0.01, 0.5, \"Domains\", va='center', rotation='vertical', fontsize=12, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(os.path.join(curr_wd, \"data/results/subfigures/\"), exist_ok=True)\n",
    "    plt.savefig(os.path.join(curr_wd, \"data/results/subfigures/fig2_G.svg\"), transparent=True)\n",
    "    plt.show()\n",
    "\n",
    "# Example call\n",
    "y_label_dict = {\n",
    "    'Serine-threonine/tyrosine-protein kinase, catalytic domain': \"Ser-Thr/Tyr-protein kinase, catalytic\"\n",
    "}\n",
    "\n",
    "plot_motif_distances(\n",
    "    proteins_with_domain_metrics_df,\n",
    "    motif_info_set_df,\n",
    "    domain_GO_dict,\n",
    "    view_limit=1250,\n",
    "    label_dict=y_label_dict,\n",
    "    show_singular_domains=True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biopy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
